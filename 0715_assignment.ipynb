{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 삼성 DS-KAIST AI Expert 프로그램\n",
    "## Week 3: 신경망 기초, 다층신경망\n",
    "\n",
    "실습 일시: 2019년 7월 15일 (월), 13:30 - 17:30\n",
    "\n",
    "담당 조교: 정종헌 (jongheonj@kaist.ac.kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "# 실습에서 사용할 모듈을 import 합니다.\n",
    "\n",
    "# IPython 상에서 matplotlib 라이브러리가 \n",
    "# 별도의 창 없이 즉시 plot을 출력할 수 있도록 설정을 변경합니다.\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "# \"즉시 실행\" (eager execution) 기능을 활성화합니다.\n",
    "# 즉시 실행 활성화로 TensorFlow를 대화형 프론트엔드(frontend)에 가깝게 만들어 줍니다.\n",
    "# 해당 기능은 TensorFlow 2.0 부터는 기본적으로 활성화됩니다. \n",
    "tf.enable_eager_execution()\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 과정에서 사용되는 도움함수를 정의합니다. \n",
    "\n",
    "def parse(line):\n",
    "    \"\"\"색깔 데이터셋의 각 라인을 파싱함\"\"\"\n",
    "\n",
    "    # 데이터셋의 각 라인은 쉼표로(,) 구분되어 있고, 다음과 같은 포맷을 가집니다.\n",
    "    #    color_name, r, g, b\n",
    "    # 따라서, `items` 는 [color_name, r, g, b]의 형태를 가지는 list입니다.\n",
    "    items = tf.string_split([line], \",\").values\n",
    "    \n",
    "    # 불러온 데이터셋의 (r, g, b)는 0~255 사이의 값을 가집니다.\n",
    "    # 여기서는 각 수치가 0~1 사이의 값을 가지도록 전처리합니다.\n",
    "    rgb = tf.string_to_number(items[1:], out_type=tf.float32) / 255.\n",
    "    \n",
    "    # color_name은 색깔의 이름을 나타내는 string입니다.\n",
    "    # string의 각 character를 숫자로 변환하고, 이를 one-hot 인코딩하여 전처리합니다.\n",
    "    color_name = items[0]\n",
    "    chars = tf.one_hot(tf.decode_raw(color_name, tf.uint8), depth=256)\n",
    "    \n",
    "    # color_name의 string 길이도 전처리로 계산하여 함께 전달합니다.\n",
    "    length = tf.cast(tf.shape(chars)[0], dtype=tf.int64)\n",
    "    \n",
    "    return rgb, chars, length\n",
    "\n",
    "def load_dataset(data_path, batch_size):\n",
    "    # 효과적인 학습 구성을 위해, .csv 형태의 데이터셋을 tf.data.Dataset으로 변환합니다:\n",
    "    #   1. 첫 헤더 줄을 생략합니다; (.skip(1))\n",
    "    #   2. 각 줄에 대해 `parse()` 함수를 적용합니다; (.map(parse))\n",
    "    #   3. 데이터를 무작위로 셔플합니다; (.shuffle(...))\n",
    "    #   3. 데이터를 배치 형태로 묶습니다 (.padded_batch(...)).\n",
    "    dataset = tf.data.TextLineDataset(data_path).skip(1).map(parse)\n",
    "    dataset = dataset.shuffle(10000).padded_batch(batch_size, padded_shapes=([None], [None, None], []))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNColorbot(tf.keras.Model):\n",
    "    \"\"\"Multi-layer (LSTM) RNN that regresses on real-valued vector labels.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_cell_sizes):\n",
    "        \"\"\"Constructs an RNNColorbot.\n",
    "\n",
    "        Args:\n",
    "            rnn_cell_sizes: list of integers denoting the size of each LSTM cell in\n",
    "                the RNN; rnn_cell_sizes[i] is the size of the i-th layer cell\n",
    "        \"\"\"\n",
    "        super(RNNColorbot, self).__init__()\n",
    "        \n",
    "                     \n",
    "        self.cells = [tf.keras.layers.LSTMCell(size) for size in rnn_cell_sizes]           \n",
    "        self.relu = L.Dense(3, activation=tf.nn.relu)       \n",
    "       \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Implements the RNN logic and prediction generation.\n",
    "\n",
    "        Args:\n",
    "            inputs: A tuple (chars, sequence_length), where chars is a batch of\n",
    "                one-hot encoded color names represented as a Tensor with dimensions\n",
    "                [batch_size, time_steps, 256] and sequence_length holds the length\n",
    "                of each character sequence (color name) as a Tensor with dimension\n",
    "                [batch_size].\n",
    "\n",
    "        Returns:\n",
    "            A tensor of dimension [batch_size, label_dimension] that is produced by\n",
    "            passing chars through a multi-layer RNN and applying a ReLU to the final\n",
    "            hidden state.\n",
    "        \"\"\"\n",
    "        (chars, sequence_length) = inputs\n",
    "        \n",
    "        # Transpose the first and second dimensions so that chars is of shape\n",
    "        # [time_steps, batch_size, dimension].\n",
    "        chars = tf.transpose(chars, [1, 0, 2])\n",
    "        \n",
    "        # The outer loop cycles through the layers of the RNN; \n",
    "        # the inner loop executes the time steps for a particular layer.\n",
    "        batch_size = int(chars.shape[1])\n",
    "        for l in range(len(self.cells)):\n",
    "            cell = self.cells[l]\n",
    "            outputs = []\n",
    "            state = cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "            \n",
    "            # Unstack the inputs to obtain a list of batches, one for each time step.\n",
    "            chars = tf.unstack(chars, axis=0)\n",
    "            \n",
    "            for ch in chars:\n",
    "                output, state = cell(ch, state)\n",
    "                outputs.append(output)\n",
    "                \n",
    "            # The outputs of this layer are the inputs of the subsequent layer.\n",
    "            chars = tf.stack(outputs, axis=0)\n",
    "            \n",
    "        # Extract the correct output (i.e., hidden state) for each example. All the\n",
    "        # character sequences in this batch were padded to the same fixed length so\n",
    "        # that they could be easily fed through the above RNN loop. The\n",
    "        # `sequence_length` vector tells us the true lengths of the character\n",
    "        # sequences, letting us obtain for each sequence the hidden state that was\n",
    "        # generated by its non-padding characters.\n",
    "        batch_range = [i for i in range(batch_size)]\n",
    "        indices = tf.stack([sequence_length - 1, batch_range], axis=1)\n",
    "        hidden_states = tf.gather_nd(chars, indices)\n",
    "        return self.relu(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습하고자 하는 모델을 구성합니다. \n",
    "# 여기서는, 2-레이어의 LSTM 셀을 사용하는 RNN을 구성할 것입니다.\n",
    "model = RNNColorbot(rnn_cell_sizes=[256, 128])\n",
    "\n",
    "# 훈련 데이터셋과 테스트 데이터셋을 로드합니다.\n",
    "train_ds = load_dataset('resource/rnn_train.csv', batch_size=64)\n",
    "test_ds = load_dataset('resource/rnn_test.csv', batch_size=64)\n",
    "\n",
    "# Adam 알고리즘을 통해 최적화를 수행하고, learning rate를 0.01로 설정합니다.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "\n",
    "# 최적화하고자 하는 loss를 정의합니다.\n",
    "def loss_object(labels, predictions):\n",
    "    return tf.reduce_mean(tf.math.squared_difference(predictions, labels))    \n",
    "\n",
    "# 학습 도중 계산되는 성능 측정값을 계산할 수 있는 연산자를 생성합니다.\n",
    "train_loss = keras.metrics.Mean(\"train_loss\")\n",
    "test_loss = keras.metrics.Mean(\"test_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, labels, chars, sequence_length):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model((chars, sequence_length))\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    \n",
    "    # model.summary()    # Check model summay\n",
    "\n",
    "def test_step(model, labels, chars, sequence_length):\n",
    "    predictions = model((chars, sequence_length))\n",
    "    test_loss(loss_object(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Epoch 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 17:13:21.834018 18620 deprecation.py:323] From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Avg. Loss: 0.754111\n",
      "[TEST] Avg. Loss: 0.0826\n",
      "===== Epoch 2 =====\n",
      "[TRAIN] Avg. Loss: 0.417236\n",
      "[TEST] Avg. Loss: 0.0755\n",
      "===== Epoch 3 =====\n",
      "[TRAIN] Avg. Loss: 0.301731\n",
      "[TEST] Avg. Loss: 0.0728\n",
      "===== Epoch 4 =====\n",
      "[TRAIN] Avg. Loss: 0.242858\n",
      "[TEST] Avg. Loss: 0.0708\n",
      "===== Epoch 5 =====\n",
      "[TRAIN] Avg. Loss: 0.206930\n",
      "[TEST] Avg. Loss: 0.0692\n",
      "===== Epoch 6 =====\n",
      "[TRAIN] Avg. Loss: 0.182500\n",
      "[TEST] Avg. Loss: 0.0679\n",
      "===== Epoch 7 =====\n",
      "[TRAIN] Avg. Loss: 0.164705\n",
      "[TEST] Avg. Loss: 0.0671\n",
      "===== Epoch 8 =====\n",
      "[TRAIN] Avg. Loss: 0.151030\n",
      "[TEST] Avg. Loss: 0.0665\n",
      "===== Epoch 9 =====\n",
      "[TRAIN] Avg. Loss: 0.140074\n",
      "[TEST] Avg. Loss: 0.0660\n",
      "===== Epoch 10 =====\n",
      "[TRAIN] Avg. Loss: 0.131001\n",
      "[TEST] Avg. Loss: 0.0658\n",
      "===== Epoch 11 =====\n",
      "[TRAIN] Avg. Loss: 0.123427\n",
      "[TEST] Avg. Loss: 0.0657\n",
      "===== Epoch 12 =====\n",
      "[TRAIN] Avg. Loss: 0.117085\n",
      "[TEST] Avg. Loss: 0.0658\n",
      "===== Epoch 13 =====\n",
      "[TRAIN] Avg. Loss: 0.111601\n",
      "[TEST] Avg. Loss: 0.0655\n",
      "===== Epoch 14 =====\n",
      "[TRAIN] Avg. Loss: 0.106622\n",
      "[TEST] Avg. Loss: 0.0656\n",
      "===== Epoch 15 =====\n",
      "[TRAIN] Avg. Loss: 0.102101\n",
      "[TEST] Avg. Loss: 0.0661\n",
      "===== Epoch 16 =====\n",
      "[TRAIN] Avg. Loss: 0.098205\n",
      "[TEST] Avg. Loss: 0.0664\n",
      "===== Epoch 17 =====\n",
      "[TRAIN] Avg. Loss: 0.094742\n",
      "[TEST] Avg. Loss: 0.0665\n",
      "===== Epoch 18 =====\n",
      "[TRAIN] Avg. Loss: 0.091402\n",
      "[TEST] Avg. Loss: 0.0663\n",
      "===== Epoch 19 =====\n",
      "[TRAIN] Avg. Loss: 0.088239\n",
      "[TEST] Avg. Loss: 0.0670\n",
      "===== Epoch 20 =====\n",
      "[TRAIN] Avg. Loss: 0.085179\n",
      "[TEST] Avg. Loss: 0.0671\n",
      "ColorBot is ready to generate colors!\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋을 20번 재방문 할 때까지 훈련을 반복합니다.\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):      \n",
    "\n",
    "    \n",
    "    print(f\"===== Epoch {epoch+1:d} =====\")\n",
    "    for labels, chars, sequence_length in train_ds:\n",
    "        train_step(model, labels, chars, sequence_length)\n",
    "    print(f\"[TRAIN] Avg. Loss: {train_loss.result():.6f}\")\n",
    "    \n",
    "    for labels, chars, sequence_length in test_ds:\n",
    "        test_step(model, labels, chars, sequence_length)\n",
    "    print(f\"[TEST] Avg. Loss: {test_loss.result():.4f}\")\n",
    "\n",
    "print(\"ColorBot is ready to generate colors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorbot(color_name):\n",
    "    _, chars, length = parse(color_name)\n",
    "    chars = tf.expand_dims(chars, 0)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    preds = tf.unstack(model((chars, length))[0])\n",
    "\n",
    "    # 학습 모델이 마지막에 ReLU activation을 사용하기 때문에, \n",
    "    # 예측값이 1이 넘을 수도 있습니다. \n",
    "    # 예측된 값이 0~1 사이의 값을 가지도록 결과값을 clipping 합니다.\n",
    "    clipped_preds = tuple(min(float(p), 1.0) for p in preds)\n",
    "    rgb = tuple(int(p * 255) for p in clipped_preds)\n",
    "    print(\"Predicted RGB values:\", rgb)\n",
    "    plt.imshow([[clipped_preds]])\n",
    "    plt.title(color_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted RGB values: (255, 220, 108)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorbot('tensorflow yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted RGB values: (249, 0, 36)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorbot('crimson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
